{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Kaggle Project 1: Breast Cancer Classification\n",
    "Don Krapohl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "I used looping to try out many hyperparameters to choose the best model over the preprocessed data. Ultimately I submitted a Random Forest model that did not do as well as expected so I did predictions using the Logistic Regression algorithm to complete my final submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "1. Joining the Kaggle Competition: Use this linkLinks to an external site. to join. Ensure your Kaggle team name matches your Canvas name. This is crucial as it's the basis for your grade. Once you've made a submission, verify your name appears correctly on the Leaderboard.\n",
    "\n",
    "2. Data Preprocessing: Split the given training dataset. Remember to exclude non-informative columns like ID.\n",
    "\n",
    "3. Model Development: Train the following classifiers: Perceptron, Logistic Regression, SVM, Decision Trees, KNN, and Random Forest. Document and evaluate each model's performance.\n",
    "\n",
    "4. Kaggle Submission: You can develop either locally or within Kaggle. Once you're satisfied with your model, create the submission.csv and submit it on Kaggle to receive a score based on the hidden test set.\n",
    "\n",
    "5. Performance: Aim to surpass a benchmark performance of 98%. If your performance is lower than 94%, you will lose the entire 70% of the grade allocated for the coding portion of this assignment.\n",
    "\n",
    "6. Notebook Submission: Whether developed locally or on Kaggle, download your notebook (or respective files) and upload it to Canvas for peer-reviews. Clearly mention your chosen classifier for the final Kaggle submission. \n",
    "\n",
    "7. Due: Submit your submission file on Kaggle and notebook on Canvas by Nov 10, 2024, 11:59 PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be training, testing, and using the following models:\n",
    "* Perceptron\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* Decision Trees\n",
    "* Random Forest\n",
    "* KNN\n",
    "\n",
    "Ref: https://scikit-learn.org/1.5/supervised_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "I will load from train.csv, explore the data for quality and distribution, remove and encode some columns, and split the data into train and test sets. I'll train multiple models for each of the classifier algorithms and capture the one of each type that has the highest accuracy. After all are trained and tested I'll select the one with the highest accuracy and highest AUC as my submission.  I'll then predict over the test.csv file and submit the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish environment\n",
    "1. Download the python venv for the project from https://github.com/dkrapohl/uwf-venv-breast-cancer/tree/main\n",
    "2. Activate the environment using the README from that repo\n",
    "3. Set the Jupyter environment to use this kernel (top right of this window)\n",
    "\n",
    "If we need to reproduce the environment the private repo for this notebook has a pip requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic dataframe and operations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# manipulation and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# measuring results\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# warning suppression\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress ConvergenceWarnings and UserWarning.  They're noise here.\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a few collections to capture the info on our different models\n",
    "\n",
    "To explore the accuracies of multiple model hyperparameters I'll be training multiple models and keeping the model from each type of classifier that has the highest accuracy.  I suspect there's an easier way to accomplish this but this is what I can do at this point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collections we'll use for our best of each type of model\n",
    "best_models = []                    # List of model instances that are our best for final evaluation\n",
    "model_accuracies = []               # The accuracies of our best models in a key-value dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll load the data into an initial dataframe to be used for exploration and the start of preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the csv training dataset to a pandas dataframe\n",
    "# The dataset is expected in the same directory as this notebook\n",
    "#   under a subfolder path datasets/breast-cancer-wisconsin-data/\n",
    "data_train = pd.read_csv('datasets/breast-cancer-wisconsin-data/train.csv')\n",
    "# Show the shape of the dataset\n",
    "data_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Output the first 5 rows of the data to see the general character and nature of the data like missing values, obvious dirty data, features with very large ranges, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90524101</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>20.66</td>\n",
       "      <td>117.80</td>\n",
       "      <td>991.7</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.13040</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.088240</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080</td>\n",
       "      <td>25.41</td>\n",
       "      <td>138.10</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.37350</td>\n",
       "      <td>0.33010</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.08503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89346</td>\n",
       "      <td>B</td>\n",
       "      <td>9.00</td>\n",
       "      <td>14.40</td>\n",
       "      <td>56.36</td>\n",
       "      <td>246.3</td>\n",
       "      <td>0.07005</td>\n",
       "      <td>0.03116</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>...</td>\n",
       "      <td>9.699</td>\n",
       "      <td>20.07</td>\n",
       "      <td>60.90</td>\n",
       "      <td>285.5</td>\n",
       "      <td>0.09861</td>\n",
       "      <td>0.05232</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.07804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>902975</td>\n",
       "      <td>B</td>\n",
       "      <td>12.21</td>\n",
       "      <td>14.09</td>\n",
       "      <td>78.78</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.08108</td>\n",
       "      <td>0.07823</td>\n",
       "      <td>0.068390</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>...</td>\n",
       "      <td>13.130</td>\n",
       "      <td>19.29</td>\n",
       "      <td>87.65</td>\n",
       "      <td>529.9</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.24310</td>\n",
       "      <td>0.30760</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>904969</td>\n",
       "      <td>B</td>\n",
       "      <td>12.34</td>\n",
       "      <td>14.95</td>\n",
       "      <td>78.29</td>\n",
       "      <td>469.1</td>\n",
       "      <td>0.08682</td>\n",
       "      <td>0.04571</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>...</td>\n",
       "      <td>13.180</td>\n",
       "      <td>16.85</td>\n",
       "      <td>84.11</td>\n",
       "      <td>533.1</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.06744</td>\n",
       "      <td>0.04921</td>\n",
       "      <td>0.04793</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.05974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id label  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  90524101     M        17.99         20.66          117.80      991.7   \n",
       "1  84358402     M        20.29         14.34          135.10     1297.0   \n",
       "2     89346     B         9.00         14.40           56.36      246.3   \n",
       "3    902975     B        12.21         14.09           78.78      462.0   \n",
       "4    904969     B        12.34         14.95           78.29      469.1   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.10360           0.13040        0.120100             0.088240   \n",
       "1          0.10030           0.13280        0.198000             0.104300   \n",
       "2          0.07005           0.03116        0.003681             0.003472   \n",
       "3          0.08108           0.07823        0.068390             0.025340   \n",
       "4          0.08682           0.04571        0.021090             0.020540   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...        21.080          25.41           138.10      1349.0   \n",
       "1  ...        22.540          16.67           152.20      1575.0   \n",
       "2  ...         9.699          20.07            60.90       285.5   \n",
       "3  ...        13.130          19.29            87.65       529.9   \n",
       "4  ...        13.180          16.85            84.11       533.1   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0           0.14820            0.37350          0.33010               0.19740   \n",
       "1           0.13740            0.20500          0.40000               0.16250   \n",
       "2           0.09861            0.05232          0.01472               0.01389   \n",
       "3           0.10260            0.24310          0.30760               0.09140   \n",
       "4           0.10480            0.06744          0.04921               0.04793   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.3060                  0.08503  \n",
       "1          0.2364                  0.07678  \n",
       "2          0.2991                  0.07804  \n",
       "3          0.2677                  0.08824  \n",
       "4          0.2298                  0.05974  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a few rows from the training data\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the data to make sure we don't have null or missing data\n",
    "\n",
    "This will give the count of null values for each column to see if we need to handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "label                      0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the count of nulls per column\n",
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "label                      0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the count of nulls per column\n",
    "data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I prefer to verify object data types. Not important here but at scale it definitely is.\n",
    "\n",
    "Sometimes numeric data come in as object, which can make lookups and indexing inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 455 entries, 0 to 454\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       455 non-null    int64  \n",
      " 1   label                    455 non-null    object \n",
      " 2   radius_mean              455 non-null    float64\n",
      " 3   texture_mean             455 non-null    float64\n",
      " 4   perimeter_mean           455 non-null    float64\n",
      " 5   area_mean                455 non-null    float64\n",
      " 6   smoothness_mean          455 non-null    float64\n",
      " 7   compactness_mean         455 non-null    float64\n",
      " 8   concavity_mean           455 non-null    float64\n",
      " 9   concave points_mean      455 non-null    float64\n",
      " 10  symmetry_mean            455 non-null    float64\n",
      " 11  fractal_dimension_mean   455 non-null    float64\n",
      " 12  radius_se                455 non-null    float64\n",
      " 13  texture_se               455 non-null    float64\n",
      " 14  perimeter_se             455 non-null    float64\n",
      " 15  area_se                  455 non-null    float64\n",
      " 16  smoothness_se            455 non-null    float64\n",
      " 17  compactness_se           455 non-null    float64\n",
      " 18  concavity_se             455 non-null    float64\n",
      " 19  concave points_se        455 non-null    float64\n",
      " 20  symmetry_se              455 non-null    float64\n",
      " 21  fractal_dimension_se     455 non-null    float64\n",
      " 22  radius_worst             455 non-null    float64\n",
      " 23  texture_worst            455 non-null    float64\n",
      " 24  perimeter_worst          455 non-null    float64\n",
      " 25  area_worst               455 non-null    float64\n",
      " 26  smoothness_worst         455 non-null    float64\n",
      " 27  compactness_worst        455 non-null    float64\n",
      " 28  concavity_worst          455 non-null    float64\n",
      " 29  concave points_worst     455 non-null    float64\n",
      " 30  symmetry_worst           455 non-null    float64\n",
      " 31  fractal_dimension_worst  455 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 113.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Verify data types to see if there's a better explicit cast for any feature\n",
    "# We're looking specifically for anything marked \"object\" as potential for casting\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the statistics about the data and their distribution.\n",
    "\n",
    "I'm looking here for any columns with differing counts and any outrageous outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.550000e+02</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.494429e+07</td>\n",
       "      <td>14.213492</td>\n",
       "      <td>19.354374</td>\n",
       "      <td>92.572791</td>\n",
       "      <td>664.583077</td>\n",
       "      <td>0.096372</td>\n",
       "      <td>0.105059</td>\n",
       "      <td>0.089651</td>\n",
       "      <td>0.049590</td>\n",
       "      <td>0.181131</td>\n",
       "      <td>...</td>\n",
       "      <td>16.411787</td>\n",
       "      <td>25.705165</td>\n",
       "      <td>108.253319</td>\n",
       "      <td>900.190549</td>\n",
       "      <td>0.132138</td>\n",
       "      <td>0.256131</td>\n",
       "      <td>0.272104</td>\n",
       "      <td>0.115820</td>\n",
       "      <td>0.288476</td>\n",
       "      <td>0.083636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.387826e+08</td>\n",
       "      <td>3.617912</td>\n",
       "      <td>4.399626</td>\n",
       "      <td>24.993837</td>\n",
       "      <td>362.603052</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.051977</td>\n",
       "      <td>0.080264</td>\n",
       "      <td>0.039412</td>\n",
       "      <td>0.027257</td>\n",
       "      <td>...</td>\n",
       "      <td>5.013790</td>\n",
       "      <td>6.289274</td>\n",
       "      <td>34.849813</td>\n",
       "      <td>595.178062</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.154821</td>\n",
       "      <td>0.204274</td>\n",
       "      <td>0.067030</td>\n",
       "      <td>0.058845</td>\n",
       "      <td>0.016646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.055210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.695835e+05</td>\n",
       "      <td>11.705000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.085000</td>\n",
       "      <td>421.950000</td>\n",
       "      <td>0.086730</td>\n",
       "      <td>0.065880</td>\n",
       "      <td>0.028860</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.980000</td>\n",
       "      <td>20.970000</td>\n",
       "      <td>83.680000</td>\n",
       "      <td>511.050000</td>\n",
       "      <td>0.117850</td>\n",
       "      <td>0.149650</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.064985</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.072090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.059780e+05</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>18.870000</td>\n",
       "      <td>86.870000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.096390</td>\n",
       "      <td>0.096610</td>\n",
       "      <td>0.063870</td>\n",
       "      <td>0.034830</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>...</td>\n",
       "      <td>14.920000</td>\n",
       "      <td>25.270000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>684.600000</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.218600</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.281500</td>\n",
       "      <td>0.080090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.910375e+06</td>\n",
       "      <td>16.090000</td>\n",
       "      <td>21.830000</td>\n",
       "      <td>105.400000</td>\n",
       "      <td>801.550000</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.130550</td>\n",
       "      <td>0.132350</td>\n",
       "      <td>0.074975</td>\n",
       "      <td>0.194900</td>\n",
       "      <td>...</td>\n",
       "      <td>19.185000</td>\n",
       "      <td>29.915000</td>\n",
       "      <td>126.900000</td>\n",
       "      <td>1122.500000</td>\n",
       "      <td>0.144800</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.091950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.937900</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.577400</td>\n",
       "      <td>0.148600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  4.550000e+02   455.000000    455.000000      455.000000   455.000000   \n",
       "mean   3.494429e+07    14.213492     19.354374       92.572791   664.583077   \n",
       "std    1.387826e+08     3.617912      4.399626       24.993837   362.603052   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.695835e+05    11.705000     16.170000       75.085000   421.950000   \n",
       "50%    9.059780e+05    13.400000     18.870000       86.870000   551.100000   \n",
       "75%    8.910375e+06    16.090000     21.830000      105.400000   801.550000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       455.000000        455.000000      455.000000           455.000000   \n",
       "mean          0.096372          0.105059        0.089651             0.049590   \n",
       "std           0.013746          0.051977        0.080264             0.039412   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086730          0.065880        0.028860             0.020335   \n",
       "50%           0.096390          0.096610        0.063870             0.034830   \n",
       "75%           0.104900          0.130550        0.132350             0.074975   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     455.000000  ...    455.000000     455.000000       455.000000   \n",
       "mean        0.181131  ...     16.411787      25.705165       108.253319   \n",
       "std         0.027257  ...      5.013790       6.289274        34.849813   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.162000  ...     12.980000      20.970000        83.680000   \n",
       "50%         0.179900  ...     14.920000      25.270000        97.660000   \n",
       "75%         0.194900  ...     19.185000      29.915000       126.900000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   455.000000        455.000000         455.000000       455.000000   \n",
       "mean    900.190549          0.132138           0.256131         0.272104   \n",
       "std     595.178062          0.022190           0.154821         0.204274   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     511.050000          0.117850           0.149650         0.110900   \n",
       "50%     684.600000          0.131600           0.218600         0.232200   \n",
       "75%    1122.500000          0.144800           0.341800         0.385700   \n",
       "max    4254.000000          0.222600           0.937900         1.170000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            455.000000      455.000000               455.000000  \n",
       "mean               0.115820        0.288476                 0.083636  \n",
       "std                0.067030        0.058845                 0.016646  \n",
       "min                0.000000        0.156600                 0.055210  \n",
       "25%                0.064985        0.250800                 0.072090  \n",
       "50%                0.101000        0.281500                 0.080090  \n",
       "75%                0.166100        0.315200                 0.091950  \n",
       "max                0.291000        0.577400                 0.148600  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic metrics about each feature, like count, mean, std, min/max, and IQR\n",
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'B']\n"
     ]
    }
   ],
   "source": [
    "# For the label column in the training set\n",
    "# Show the unique values of the training labels\n",
    "print(data_train['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust columns as needed\n",
    "\n",
    "We need to remove label and ID from the training data and encode the class labels from string to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the result column from the input parameters\n",
    "# also remove the ID column. It carries no signal.\n",
    "X_train_without_label = data_train.drop('label', axis=1).drop('id', axis=1)\n",
    "\n",
    "# Assign class labels for the input data\n",
    "y_labels = data_train['label']      # assign the labels we'll encode in the next block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels in y_train. Note we have not done train/test split yet.\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and scale the data\n",
    "\n",
    "Here I'll be splitting the data to be 70% training set, 30% test set. I then scale the data using the Standard Scaler to make all the data within the same range having 0 as the mean and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train test split\n",
    "X_train, X_test, y_train, y_test =    train_test_split(X_train_without_label, y_train,\n",
    "    test_size=0.3, \n",
    "    random_state=17, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "# We split before we scale so the scaler has no knowledge of the test set\n",
    "#   This helps to verify that the scaling is likely to be appropriate for the range of real-world values.\n",
    "\n",
    "# Scaling will be important especially for Perceptron, Logistic Regression, and KNN\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Train and Test\n",
    "\n",
    "Train the Perceptron with different hyperparameters. I'm going from smallest eta to largest because if this was used at scale I'd prefer the largest eta I can get for the best accuracy. This is based on my understanding that lower eta values take longer to converge on a solution.\n",
    "\n",
    "This algorithm will be one of the simplest to train but the data have to be linearly separable or we'll never converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron (eta=0.005)\t0.9635\n",
      "Perceptron (eta=0.01)\t0.9635\n",
      "Perceptron (eta=0.03)\t0.9635\n",
      "Perceptron (eta=0.05)\t0.9635\n",
      "Perceptron (eta=0.07)\t0.9635\n",
      "Perceptron (eta=0.1)\t0.9635\n",
      "Perceptron (eta=0.14)\t0.9635\n",
      "Perceptron (eta=0.18)\t0.9635\n",
      "Perceptron (eta=0.25)\t0.9635\n",
      "Perceptron (eta=0.4)\t0.9635\n",
      "Perceptron (eta=0.6)\t0.9635\n",
      "Perceptron (eta=0.8)\t0.9635\n",
      "Perceptron (eta=1.0)\t0.9635\n",
      "Perceptron (eta=2.0)\t0.9635\n",
      "Perceptron (eta=5.0)\t0.9635\n"
     ]
    }
   ],
   "source": [
    "# In a loop over 15 values, train a Perceptron with different etas and capture the accuracies\n",
    "etas = [0.005, 0.01, 0.03, 0.05, 0.07, 0.1, 0.14, 0.18, 0.25, 0.4, 0.6, 0.8, 1.0, 2.0, 5.0]  # eta values to try\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the highest eta as our \"best\" model\n",
    "preceptron_highest_accuracy=0\n",
    "perceptron_highest_test=0\n",
    "perceptron_highest_eta=0\n",
    "\n",
    "for eta in etas:\n",
    "    perc_model = Perceptron(eta0=eta, max_iter = 1000 )   # create a perceptron\n",
    "    perc_model.fit(X_train_scaled, y_train)                                    # train it\n",
    "    \n",
    "    # Collect info on training results if desired\n",
    "    #model_train_score = perc_model.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "    #print(\"{}\\t{}\".format(\"Perceptron train (eta={0})\".format(eta), \"{:.4f}\".format(model_train_score)))\n",
    "\n",
    "    # Collect info on test results\n",
    "    y_pred = perc_model.predict(X_test_scaled)  \n",
    "    model_test_score = accuracy_score(y_test, y_pred)                    # get the model accuracy\n",
    "  \n",
    "    # Print the accuracies for each of the model params so far.   \n",
    "    print(\"{}\\t{}\".format(\"Perceptron (eta={0})\".format(eta), \"{:.4f}\".format(model_test_score)))\n",
    "        \n",
    "    # Also change the \"best\" model info if appropriate\n",
    "    if model_test_score >= perceptron_highest_test:  # only update if the score is better or equal to\n",
    "        preceptron_highest_accuracy = model_test_score      # store the test score for this model\n",
    "        perceptron_highest_eta = eta                        # store the best eta\n",
    "        test_predictions = y_pred                           # store test predictions\n",
    "        perceptron_best_model = perc_model                  # store the best model\n",
    "        perceptron_highest_test = model_test_score          # update our highest score\n",
    "        \n",
    "best_models.append(perceptron_best_model)                   # add to our \"best model\" collection\n",
    "model_accuracies.append(preceptron_highest_accuracy)        # add the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each algorithm section I will output the accuracy, confusion matrix, and F1 score for both classes to verify that the results are reasonable and further inform a final decision.\n",
    "\n",
    "This being a health study I would also want to determine how much we can accept false positives and false negatives but that's going to be out of scope for this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: accuracy 0.9635, eta 5.0\n",
      "Model Confusion Matrix:\n",
      " [[84  2]\n",
      " [ 3 48]]\n",
      "Train data F1-Score for class '1': 0.9504950495049505\n",
      "Train data F1-Score for class '0': 0.9710982658959537\n"
     ]
    }
   ],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: accuracy {}, eta {}\".format(\"{:.4f}\".format(preceptron_highest_accuracy), perceptron_highest_eta))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Train and Test\n",
    "\n",
    "As with Perceptron I'm looping through hyperparameters and training multiple models, keeping the \"best\" based on accuracy. The secondary consideration is that I will prefer the lowest C value as lower C values make simpler models.\n",
    "\n",
    "This model assumes linearity in independent variables and performs well if the data are linearly separable. It'll also give use proababilities on the class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (solver=lbfgs)\t0.9781\n",
      "Logistic Regression (solver=lbfgs)\t0.9781\n",
      "Logistic Regression (solver=lbfgs)\t0.9708\n",
      "Logistic Regression (solver=lbfgs)\t0.9708\n",
      "Logistic Regression (solver=lbfgs)\t0.9708\n",
      "Logistic Regression (solver=lbfgs)\t0.9781\n",
      "Logistic Regression (solver=lbfgs)\t0.9781\n",
      "Logistic Regression (solver=lbfgs)\t0.9781\n",
      "Logistic Regression (solver=lbfgs)\t0.9781\n",
      "Logistic Regression (solver=lbfgs)\t0.9781\n",
      "Logistic Regression (solver=lbfgs)\t0.9781\n",
      "Logistic Regression (solver=lbfgs)\t0.9562\n",
      "Logistic Regression (solver=lbfgs)\t0.8759\n",
      "Logistic Regression (solver=lbfgs)\t0.6350\n",
      "Logistic Regression (solver=liblinear)\t0.9781\n",
      "Logistic Regression (solver=liblinear)\t0.9708\n",
      "Logistic Regression (solver=liblinear)\t0.9708\n",
      "Logistic Regression (solver=liblinear)\t0.9708\n",
      "Logistic Regression (solver=liblinear)\t0.9708\n",
      "Logistic Regression (solver=liblinear)\t0.9781\n",
      "Logistic Regression (solver=liblinear)\t0.9781\n",
      "Logistic Regression (solver=liblinear)\t0.9781\n",
      "Logistic Regression (solver=liblinear)\t0.9781\n",
      "Logistic Regression (solver=liblinear)\t0.9854\n",
      "Logistic Regression (solver=liblinear)\t0.9854\n",
      "Logistic Regression (solver=liblinear)\t0.9781\n",
      "Logistic Regression (solver=liblinear)\t0.9416\n",
      "Logistic Regression (solver=liblinear)\t0.9416\n",
      "Logistic Regression (solver=newton-cg)\t0.9781\n",
      "Logistic Regression (solver=newton-cg)\t0.9708\n",
      "Logistic Regression (solver=newton-cg)\t0.9708\n",
      "Logistic Regression (solver=newton-cg)\t0.9708\n",
      "Logistic Regression (solver=newton-cg)\t0.9708\n",
      "Logistic Regression (solver=newton-cg)\t0.9781\n",
      "Logistic Regression (solver=newton-cg)\t0.9781\n",
      "Logistic Regression (solver=newton-cg)\t0.9781\n",
      "Logistic Regression (solver=newton-cg)\t0.9781\n",
      "Logistic Regression (solver=newton-cg)\t0.9781\n",
      "Logistic Regression (solver=newton-cg)\t0.9781\n",
      "Logistic Regression (solver=newton-cg)\t0.9562\n",
      "Logistic Regression (solver=newton-cg)\t0.8759\n",
      "Logistic Regression (solver=newton-cg)\t0.6350\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9781\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9708\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9708\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9708\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9708\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9781\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9781\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9781\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9781\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9781\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9781\n",
      "Logistic Regression (solver=newton-cholesky)\t0.9562\n",
      "Logistic Regression (solver=newton-cholesky)\t0.8759\n",
      "Logistic Regression (solver=newton-cholesky)\t0.6350\n",
      "Logistic Regression (solver=sag)\t0.9781\n",
      "Logistic Regression (solver=sag)\t0.9781\n",
      "Logistic Regression (solver=sag)\t0.9781\n",
      "Logistic Regression (solver=sag)\t0.9781\n",
      "Logistic Regression (solver=sag)\t0.9781\n",
      "Logistic Regression (solver=sag)\t0.9854\n",
      "Logistic Regression (solver=sag)\t0.9854\n",
      "Logistic Regression (solver=sag)\t0.9927\n",
      "Logistic Regression (solver=sag)\t0.9854\n",
      "Logistic Regression (solver=sag)\t0.9781\n",
      "Logistic Regression (solver=sag)\t0.9781\n",
      "Logistic Regression (solver=sag)\t0.9562\n",
      "Logistic Regression (solver=sag)\t0.8759\n",
      "Logistic Regression (solver=sag)\t0.6350\n",
      "Logistic Regression (solver=saga)\t0.9854\n",
      "Logistic Regression (solver=saga)\t0.9854\n",
      "Logistic Regression (solver=saga)\t0.9854\n",
      "Logistic Regression (solver=saga)\t0.9927\n",
      "Logistic Regression (solver=saga)\t0.9927\n",
      "Logistic Regression (solver=saga)\t0.9927\n",
      "Logistic Regression (solver=saga)\t0.9927\n",
      "Logistic Regression (solver=saga)\t0.9927\n",
      "Logistic Regression (solver=saga)\t0.9927\n",
      "Logistic Regression (solver=saga)\t0.9781\n",
      "Logistic Regression (solver=saga)\t0.9781\n",
      "Logistic Regression (solver=saga)\t0.9562\n",
      "Logistic Regression (solver=saga)\t0.8759\n",
      "Logistic Regression (solver=saga)\t0.6350\n"
     ]
    }
   ],
   "source": [
    "# In a loop over several values, train an SVM with different C values and capture the accuracies\n",
    "# We prefer lower C for better power so we'll only update if accuracy is higher and C lower\n",
    "\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "cs = [100.0, 50.0, 20.0, 10.0, 5.0, 3.0, 2.0, 1.0, 0.75, 0.5, 0.1, 0.01, 0.001, 0.0001]  # C values to try\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the lowest C as our \"best\" model\n",
    "lr_highest_accuracy=0\n",
    "lr_lowest_c=1000.0\n",
    "\n",
    "# Try all SVM kernels\n",
    "for solver in solvers:\n",
    "    # Try the range of C values\n",
    "    for c in cs:\n",
    "        # Initialize and train the SVM model\n",
    "        logreg_model = LogisticRegression(solver=solver, C=c, random_state = 17)\n",
    "        logreg_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Collect info on training results if desired\n",
    "        # model_train_score = logreg_model.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "        # print(\"{}\\t{}\".format(\"Logistic Regression (solver={})\".format(solver), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # Make predictions using training data\n",
    "        y_pred = logreg_model.predict(X_test_scaled)\n",
    "        model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Print the accuracies for each of the model params so far.   \n",
    "        print(\"{}\\t{}\".format(\"Logistic Regression (solver={})\".format(solver), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # we want the lowest C for better generalization so only keep\n",
    "        #   accuracy if it's better but C is lower\n",
    "        if model_test_score >= lr_highest_accuracy: # we're in a list with decreasing values so don't need to check C\n",
    "            test_predictions = y_pred                   # store test predictions\n",
    "            lr_lowest_c = c                             # store the lowest C\n",
    "            lr_best_model = logreg_model                # store the best model\n",
    "            lr_best_solver = solver                     # store the best solver\n",
    "            lr_highest_accuracy = model_test_score       # update our highest score\n",
    "\n",
    "best_models.append(lr_best_model)                       # add to our \"best model\" collection      \n",
    "model_accuracies.append(lr_highest_accuracy)                # add the accuracy      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: saga solver, c 0.0001, accuracy 0.9927\n",
      "Model Confusion Matrix:\n",
      " [[86  0]\n",
      " [ 1 50]]\n",
      "Train data F1-Score for class '1': 0.9900990099009901\n",
      "Train data F1-Score for class '0': 0.9942196531791907\n"
     ]
    }
   ],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} solver, c {}, accuracy {}\".format(lr_best_solver, c, \"{:.4f}\".format(lr_highest_accuracy)))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Train and Test\n",
    "\n",
    "As with Logistic Regression, looping to train multiple models, keeping the one with the highest accuracy for the lowest C value.  C value again we prefer lower C as it makes for simpler models.\n",
    "\n",
    "This model will be computationally more expensive than the others, especially since I'm testing multiple C values on all kernels. The algorithm is more flexible in its ability to model both linear and non-linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (kernel=linear, C=100.0)\t0.9708\n",
      "SVM (kernel=linear, C=50.0)\t0.9708\n",
      "SVM (kernel=linear, C=20.0)\t0.9781\n",
      "SVM (kernel=linear, C=10.0)\t0.9635\n",
      "SVM (kernel=linear, C=5.0)\t0.9708\n",
      "SVM (kernel=linear, C=3.0)\t0.9708\n",
      "SVM (kernel=linear, C=2.0)\t0.9708\n",
      "SVM (kernel=linear, C=1.0)\t0.9781\n",
      "SVM (kernel=linear, C=0.75)\t0.9781\n",
      "SVM (kernel=linear, C=0.5)\t0.9781\n",
      "SVM (kernel=linear, C=0.1)\t0.9854\n",
      "SVM (kernel=linear, C=0.01)\t0.9635\n",
      "SVM (kernel=linear, C=0.001)\t0.9562\n",
      "SVM (kernel=linear, C=0.0001)\t0.6350\n",
      "SVM (kernel=rbf, C=100.0)\t0.9781\n",
      "SVM (kernel=rbf, C=50.0)\t0.9781\n",
      "SVM (kernel=rbf, C=20.0)\t0.9781\n",
      "SVM (kernel=rbf, C=10.0)\t0.9854\n",
      "SVM (kernel=rbf, C=5.0)\t0.9854\n",
      "SVM (kernel=rbf, C=3.0)\t0.9854\n",
      "SVM (kernel=rbf, C=2.0)\t0.9854\n",
      "SVM (kernel=rbf, C=1.0)\t0.9708\n",
      "SVM (kernel=rbf, C=0.75)\t0.9708\n",
      "SVM (kernel=rbf, C=0.5)\t0.9708\n",
      "SVM (kernel=rbf, C=0.1)\t0.9489\n",
      "SVM (kernel=rbf, C=0.01)\t0.6277\n",
      "SVM (kernel=rbf, C=0.001)\t0.6277\n",
      "SVM (kernel=rbf, C=0.0001)\t0.6277\n",
      "SVM (kernel=poly, C=100.0)\t0.9635\n",
      "SVM (kernel=poly, C=50.0)\t0.9708\n",
      "SVM (kernel=poly, C=20.0)\t0.9708\n",
      "SVM (kernel=poly, C=10.0)\t0.9562\n",
      "SVM (kernel=poly, C=5.0)\t0.9416\n",
      "SVM (kernel=poly, C=3.0)\t0.9197\n",
      "SVM (kernel=poly, C=2.0)\t0.9124\n",
      "SVM (kernel=poly, C=1.0)\t0.9051\n",
      "SVM (kernel=poly, C=0.75)\t0.8978\n",
      "SVM (kernel=poly, C=0.5)\t0.8759\n",
      "SVM (kernel=poly, C=0.1)\t0.8613\n",
      "SVM (kernel=poly, C=0.01)\t0.7372\n",
      "SVM (kernel=poly, C=0.001)\t0.6569\n",
      "SVM (kernel=poly, C=0.0001)\t0.6277\n",
      "SVM (kernel=sigmoid, C=100.0)\t0.8905\n",
      "SVM (kernel=sigmoid, C=50.0)\t0.8905\n",
      "SVM (kernel=sigmoid, C=20.0)\t0.8978\n",
      "SVM (kernel=sigmoid, C=10.0)\t0.9051\n",
      "SVM (kernel=sigmoid, C=5.0)\t0.9343\n",
      "SVM (kernel=sigmoid, C=3.0)\t0.9343\n",
      "SVM (kernel=sigmoid, C=2.0)\t0.9343\n",
      "SVM (kernel=sigmoid, C=1.0)\t0.9635\n",
      "SVM (kernel=sigmoid, C=0.75)\t0.9562\n",
      "SVM (kernel=sigmoid, C=0.5)\t0.9635\n",
      "SVM (kernel=sigmoid, C=0.1)\t0.9635\n",
      "SVM (kernel=sigmoid, C=0.01)\t0.8540\n",
      "SVM (kernel=sigmoid, C=0.001)\t0.6277\n",
      "SVM (kernel=sigmoid, C=0.0001)\t0.6277\n"
     ]
    }
   ],
   "source": [
    "# In a loop over several values, train an SVM with different C values and capture the accuracies\n",
    "# We prefer lower C for better power so we'll only update if accuracy is higher and C lower\n",
    "cs = [100.0, 50.0, 20.0, 10.0, 5.0, 3.0, 2.0, 1.0, 0.75, 0.5, 0.1, 0.01, 0.001, 0.0001]  # C values to try\n",
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the highest eta as our \"best\" model\n",
    "svm_highest_accuracy=0\n",
    "svm_lowest_c=1000\n",
    "\n",
    "# Try all SVM kernels\n",
    "for kernel in kernels:\n",
    "    # Loop through C values largest to smallest, train and test each\n",
    "    for c in cs:\n",
    "        # Initialize and train the SVM model\n",
    "        linear_svm = SVC(kernel=kernel, C=c, random_state=17)\n",
    "        linear_svm.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Collect info on training results if desired\n",
    "        # model_train_score = linear_svm.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "        # print(\"{}\\t{}\".format(\"SVM Train (kernel={}, C={})\".format(kernel, c), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # Make predictions using training data\n",
    "        y_pred = linear_svm.predict(X_test_scaled)\n",
    "        model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Print the accuracies for each of the model params so far.   \n",
    "        print(\"{}\\t{}\".format(\"SVM (kernel={}, C={})\".format(kernel, c), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # we want the lowest C for better generalization so only keep\n",
    "        #   accuracy if it's better but C is lower\n",
    "        if model_test_score >= svm_highest_accuracy: # we're in a list with decreasing values so don't need to check C\n",
    "            svm_lowest_c = c                            # store lowest C\n",
    "            test_predictions = y_pred                   # store test predictions\n",
    "            svm_best_model = linear_svm                 # store the best model\n",
    "            svm_best_kernel = kernel                    # store the best kernel\n",
    "            svm_highest_accuracy = model_test_score     # update our highest score\n",
    "\n",
    "best_models.append(svm_best_model)                      # add to our \"best model\" collection   \n",
    "model_accuracies.append(svm_highest_accuracy)           # add the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: rbf kernel, accuracy 0.9854, C 2.0\n",
      "Model Confusion Matrix:\n",
      " [[85  1]\n",
      " [ 1 50]]\n",
      "Train data F1-Score for class '1': 0.9803921568627451\n",
      "Train data F1-Score for class '0': 0.9883720930232558\n"
     ]
    }
   ],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} kernel, accuracy {}, C {}\".format(svm_best_kernel, \"{:.4f}\".format(svm_highest_accuracy), \n",
    "                                                        svm_lowest_c))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees Train and Test\n",
    "\n",
    "With Decision Trees we're testing different splitting algorithms as well as model depth keeping the one with the highest accuracy and the lowest depth.  Lowest depth is selected as it makes for the simpler model.\n",
    "\n",
    "This algorithm should be the easiest to interpret and captures non-linear relationships but it's prone to overfitting.  It's also at risk of creating biased trees if the classes are imbalanced but the classes here are relatively equally represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (criterion=gini, depth=50)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=49)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=48)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=47)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=46)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=45)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=44)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=43)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=42)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=41)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=40)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=39)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=38)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=37)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=36)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=35)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=34)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=33)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=32)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=31)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=30)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=29)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=28)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=27)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=26)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=25)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=24)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=23)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=22)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=21)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=20)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=19)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=18)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=17)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=16)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=15)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=14)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=13)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=12)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=11)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=10)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=9)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=8)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=7)\t0.9270\n",
      "Decision Tree (criterion=gini, depth=6)\t0.9489\n",
      "Decision Tree (criterion=gini, depth=5)\t0.9416\n",
      "Decision Tree (criterion=gini, depth=4)\t0.9416\n",
      "Decision Tree (criterion=gini, depth=3)\t0.9416\n",
      "Decision Tree (criterion=gini, depth=2)\t0.9416\n",
      "Decision Tree (criterion=entropy, depth=50)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=49)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=48)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=47)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=46)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=45)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=44)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=43)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=42)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=41)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=40)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=39)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=38)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=37)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=36)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=35)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=34)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=33)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=32)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=31)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=30)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=29)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=28)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=27)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=26)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=25)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=24)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=23)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=22)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=21)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=20)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=19)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=18)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=17)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=16)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=15)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=14)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=13)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=12)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=11)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=10)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=9)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=8)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=7)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=6)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=5)\t0.9343\n",
      "Decision Tree (criterion=entropy, depth=4)\t0.9270\n",
      "Decision Tree (criterion=entropy, depth=3)\t0.9124\n",
      "Decision Tree (criterion=entropy, depth=2)\t0.9197\n",
      "Decision Tree (criterion=log_loss, depth=50)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=49)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=48)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=47)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=46)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=45)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=44)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=43)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=42)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=41)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=40)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=39)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=38)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=37)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=36)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=35)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=34)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=33)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=32)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=31)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=30)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=29)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=28)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=27)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=26)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=25)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=24)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=23)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=22)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=21)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=20)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=19)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=18)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=17)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=16)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=15)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=14)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=13)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=12)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=11)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=10)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=9)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=8)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=7)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=6)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=5)\t0.9343\n",
      "Decision Tree (criterion=log_loss, depth=4)\t0.9270\n",
      "Decision Tree (criterion=log_loss, depth=3)\t0.9124\n",
      "Decision Tree (criterion=log_loss, depth=2)\t0.9197\n"
     ]
    }
   ],
   "source": [
    "# In a loop over several values, train a decision tree with different split criteria and depths and capture the accuracies\n",
    "# We prefer lower C for better power so we'll only update if accuracy is higher and depth lower\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the lowest depth as our \"best\" model\n",
    "dtree_highest_accuracy=0\n",
    "dtree_lowest_depth=1000\n",
    "dtree_best_criterion=''\n",
    "\n",
    "# Try all SVM kernels\n",
    "for criterion in criteria:\n",
    "    # Loop through depth values smallest to largest, train and test each\n",
    "    for depth in range(50, 1, -1):   # Allow up to depth 5 starting at 5 and down to 1\n",
    "        # Initialize and train the decision tree model\n",
    "        decision_tree = DecisionTreeClassifier(criterion=criterion, max_depth=depth, random_state=17)\n",
    "        decision_tree.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Collect info on training results if desired\n",
    "        # model_train_score = decision_tree.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "        # print(\"{}\\t{}\".format(\"Decision Tree Train (criterion={}, depth={})\".format(criterion, depth), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # Make predictions using training data\n",
    "        y_pred = decision_tree.predict(X_test_scaled)\n",
    "        model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Print the accuracies for each of the model params so far.   \n",
    "        print(\"{}\\t{}\".format(\"Decision Tree (criterion={}, depth={})\".format(criterion, depth), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # we want the lowest C for better generalization so only keep\n",
    "        #   accuracy if it's better but C is lower\n",
    "        if model_test_score >= dtree_highest_accuracy:\n",
    "            dtree_lowest_depth = depth              # store lowest depth\n",
    "            test_predictions = y_pred               # store test predictions\n",
    "            dtree_best_model = decision_tree        # store the best model\n",
    "            dtree_best_criterion = criterion        # store the best kernel\n",
    "            dtree_highest_accuracy = model_test_score   # update our highest score\n",
    "\n",
    "best_models.append(dtree_best_model)                # add to our \"best model\" collection\n",
    "model_accuracies.append(dtree_highest_accuracy)     # add the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: gini criterion, depth 6, accuracy 0.9489\n",
      "Model Confusion Matrix:\n",
      " [[80  6]\n",
      " [ 1 50]]\n",
      "Train data F1-Score for class '1': 0.9345794392523364\n",
      "Train data F1-Score for class '0': 0.9580838323353293\n"
     ]
    }
   ],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} criterion, depth {}, accuracy {}\".format(dtree_best_criterion, dtree_lowest_depth, \n",
    "                                                               \"{:.4f}\".format(dtree_highest_accuracy)))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Train and Test\n",
    "\n",
    "This is very much like Decision Trees except we're tuning splitting criteria as well as the number of estimators used.  We'll prefer fewer estimators for simpler models.\n",
    "\n",
    "The Random Forest algorithm is harder to interpret because it's an ensemble of decision trees but it's less likely to overfit. It can be harder to compute than a single or a few decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test (criterion=gini, estimators=500)\t0.9854\n",
      "Random Forest Test (criterion=gini, estimators=450)\t0.9854\n",
      "Random Forest Test (criterion=gini, estimators=400)\t0.9854\n",
      "Random Forest Test (criterion=gini, estimators=350)\t0.9854\n",
      "Random Forest Test (criterion=gini, estimators=300)\t0.9854\n",
      "Random Forest Test (criterion=gini, estimators=250)\t0.9854\n",
      "Random Forest Test (criterion=gini, estimators=200)\t0.9854\n",
      "Random Forest Test (criterion=gini, estimators=150)\t0.9781\n",
      "Random Forest Test (criterion=gini, estimators=100)\t0.9708\n",
      "Random Forest Test (criterion=entropy, estimators=500)\t0.9854\n",
      "Random Forest Test (criterion=entropy, estimators=450)\t0.9854\n",
      "Random Forest Test (criterion=entropy, estimators=400)\t0.9854\n",
      "Random Forest Test (criterion=entropy, estimators=350)\t0.9854\n",
      "Random Forest Test (criterion=entropy, estimators=300)\t0.9854\n",
      "Random Forest Test (criterion=entropy, estimators=250)\t0.9781\n",
      "Random Forest Test (criterion=entropy, estimators=200)\t0.9781\n",
      "Random Forest Test (criterion=entropy, estimators=150)\t0.9781\n",
      "Random Forest Test (criterion=entropy, estimators=100)\t0.9781\n",
      "Random Forest Test (criterion=log_loss, estimators=500)\t0.9854\n",
      "Random Forest Test (criterion=log_loss, estimators=450)\t0.9854\n",
      "Random Forest Test (criterion=log_loss, estimators=400)\t0.9854\n",
      "Random Forest Test (criterion=log_loss, estimators=350)\t0.9854\n",
      "Random Forest Test (criterion=log_loss, estimators=300)\t0.9854\n",
      "Random Forest Test (criterion=log_loss, estimators=250)\t0.9781\n",
      "Random Forest Test (criterion=log_loss, estimators=200)\t0.9781\n",
      "Random Forest Test (criterion=log_loss, estimators=150)\t0.9781\n",
      "Random Forest Test (criterion=log_loss, estimators=100)\t0.9781\n"
     ]
    }
   ],
   "source": [
    "# In a loop over several values, train a random forest with different split criteria and estimator count and capture the accuracies\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the lowest number of estimators as our \"best\" model\n",
    "rforest_highest_accuracy=0\n",
    "rforest_lowest_estimators=1000\n",
    "rforest_best_criterion=''\n",
    "\n",
    "# Try all random forest split criteria\n",
    "for criterion in criteria:\n",
    "    # Loop through depth values smallest to largest, train and test each\n",
    "    for estimators in range(500, 50, -50):   # Allow up to 500 estimators decreasing by 50 each loop\n",
    "        # Initialize and train the decision tree model\n",
    "        random_forest = RandomForestClassifier(criterion=criterion, n_estimators=estimators, random_state=17)\n",
    "        random_forest.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Collect info on training results if desired\n",
    "        # model_train_score = random_forest.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "        # print(\"{}\\t{}\".format(\"Random Forest Train (criterion={}, estimators={})\".format(criterion, estimators), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # Make predictions using training data\n",
    "        y_pred = random_forest.predict(X_test_scaled)\n",
    "        model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Print the accuracies for each of the model params so far.   \n",
    "        print(\"{}\\t{}\".format(\"Random Forest Test (criterion={}, estimators={})\".format(criterion, estimators), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # we want the lowest number of estimators for better generalization \n",
    "        if model_test_score >= rforest_highest_accuracy:\n",
    "            rforest_lowest_estimators = estimators  # store lowest number of estimators\n",
    "            test_predictions = y_pred               # store test predictions\n",
    "            rforest_best_model = random_forest      # store the best model\n",
    "            rforest_best_criterion = criterion      # store the best criterion\n",
    "            rforest_highest_accuracy = model_test_score # update our highest score\n",
    "            \n",
    "best_models.append(rforest_best_model)              # add to our \"best model\" collection        \n",
    "model_accuracies.append(rforest_highest_accuracy)   # add the accuracy    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: log_loss criterion, estimators 300, accuracy 0.9854\n",
      "Model Confusion Matrix:\n",
      " [[84  2]\n",
      " [ 0 51]]\n",
      "Train data F1-Score for class '1': 0.9807692307692307\n",
      "Train data F1-Score for class '0': 0.9882352941176471\n"
     ]
    }
   ],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} criterion, estimators {}, accuracy {}\".format(rforest_best_criterion, rforest_lowest_estimators, \n",
    "                                                                    \"{:.4f}\".format(rforest_highest_accuracy)))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Train and Test\n",
    "\n",
    "This is simpler as I'm only tuning the number of neighbors and keeping the one with the highest accuracy. We'll prefer the model with the fewest neighbors.\n",
    "\n",
    "KNN, while computational a bit expensive is simple for this problem and doesn't appear to require much tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test (neighbors=2)\t0.9489\n",
      "KNN Test (neighbors=3)\t0.9635\n",
      "KNN Test (neighbors=4)\t0.9635\n",
      "KNN Test (neighbors=5)\t0.9708\n",
      "KNN Test (neighbors=6)\t0.9416\n",
      "KNN Test (neighbors=7)\t0.9635\n",
      "KNN Test (neighbors=8)\t0.9562\n",
      "KNN Test (neighbors=9)\t0.9708\n",
      "KNN Test (neighbors=10)\t0.9635\n",
      "KNN Test (neighbors=11)\t0.9635\n",
      "KNN Test (neighbors=12)\t0.9635\n",
      "KNN Test (neighbors=13)\t0.9708\n",
      "KNN Test (neighbors=14)\t0.9635\n",
      "KNN Test (neighbors=15)\t0.9635\n",
      "KNN Test (neighbors=16)\t0.9489\n",
      "KNN Test (neighbors=17)\t0.9489\n",
      "KNN Test (neighbors=18)\t0.9489\n",
      "KNN Test (neighbors=19)\t0.9489\n",
      "KNN Test (neighbors=20)\t0.9489\n",
      "KNN Test (neighbors=21)\t0.9635\n",
      "KNN Test (neighbors=22)\t0.9635\n",
      "KNN Test (neighbors=23)\t0.9562\n",
      "KNN Test (neighbors=24)\t0.9489\n",
      "KNN Test (neighbors=25)\t0.9489\n",
      "KNN Test (neighbors=26)\t0.9489\n",
      "KNN Test (neighbors=27)\t0.9562\n",
      "KNN Test (neighbors=28)\t0.9562\n",
      "KNN Test (neighbors=29)\t0.9562\n",
      "KNN Test (neighbors=30)\t0.9562\n",
      "KNN Test (neighbors=31)\t0.9562\n",
      "KNN Test (neighbors=32)\t0.9489\n",
      "KNN Test (neighbors=33)\t0.9489\n",
      "KNN Test (neighbors=34)\t0.9489\n",
      "KNN Test (neighbors=35)\t0.9562\n",
      "KNN Test (neighbors=36)\t0.9489\n",
      "KNN Test (neighbors=37)\t0.9489\n",
      "KNN Test (neighbors=38)\t0.9489\n",
      "KNN Test (neighbors=39)\t0.9489\n",
      "KNN Test (neighbors=40)\t0.9489\n",
      "KNN Test (neighbors=41)\t0.9489\n",
      "KNN Test (neighbors=42)\t0.9489\n",
      "KNN Test (neighbors=43)\t0.9489\n",
      "KNN Test (neighbors=44)\t0.9489\n",
      "KNN Test (neighbors=45)\t0.9489\n",
      "KNN Test (neighbors=46)\t0.9489\n",
      "KNN Test (neighbors=47)\t0.9489\n",
      "KNN Test (neighbors=48)\t0.9489\n",
      "KNN Test (neighbors=49)\t0.9562\n"
     ]
    }
   ],
   "source": [
    "# In a loop over several values, train a knn movel with different number of neighbors\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the lowest # nieghbors as our \"best\" model\n",
    "knn_highest_accuracy=0\n",
    "knn_lowest_neighbors=1\n",
    "\n",
    "# Loop through neighbor values, train and test each\n",
    "for n_neighbors in range(2, 50):   # Allow up to 50 neighbors increasing by 1 each loop\n",
    "    # Initialize and train the decision tree model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Collect info on training results if desired\n",
    "    # model_train_score = knn_model.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "    # print(\"{}\\t{}\".format(\"KNN Train (neighbors={})\".format(n_neighbors), \"{:.4f}\".format(model_test_score)))\n",
    "        \n",
    "    # Make predictions using training data\n",
    "    y_pred = knn_model.predict(X_test_scaled)\n",
    "    model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print the accuracies for each of the model params so far.   \n",
    "    print(\"{}\\t{}\".format(\"KNN Test (neighbors={})\".format(n_neighbors), \"{:.4f}\".format(model_test_score)))\n",
    "        \n",
    "    # we want the lowest number of estimators for better generalization \n",
    "    if model_test_score >= knn_highest_accuracy:\n",
    "        knn_lowest_neighbors = n_neighbors      # store lowest number of estimators\n",
    "        test_predictions = y_pred               # store test predictions\n",
    "        knn_best_model = knn_model              # store the best model\n",
    "        knn_highest_accuracy = model_test_score # update our highest score\n",
    "\n",
    "best_models.append(knn_best_model)              # add to our \"best model\" collection  \n",
    "model_accuracies.append(knn_highest_accuracy)   # add the accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: 13 neighbors, accuracy 0.9708\n",
      "Model Confusion Matrix:\n",
      " [[86  0]\n",
      " [ 4 47]]\n",
      "Train data F1-Score for class '1': 0.9591836734693877\n",
      "Train data F1-Score for class '0': 0.9772727272727273\n"
     ]
    }
   ],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} neighbors, accuracy {}\".format(knn_lowest_neighbors, \"{:.4f}\".format(knn_highest_accuracy)))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Selection\n",
    "\n",
    "Here I enumerate through the best model for each type of classifier; do cross validation; and output AUC, accuracy, and info on the hyperparameters of our best of each type of model.  I'll use this to select the best model.\n",
    "\n",
    "The best model I will choose is the one with the highest AUC that has the lowest standard deviation and the one with the highest accuracy.\n",
    "\n",
    "After this I will load the test.csv we need to predict over, do predictions, encode the class label outputs of the predictions, and save the final csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.94 (+/- 0.05) [Accuracy 0.9635] Perceptron(eta0=5.0)\n",
      "ROC AUC: 0.91 (+/- 0.07) [Accuracy 0.9927] LogisticRegression(C=0.75, random_state=17, solver='saga')\n",
      "ROC AUC: 0.97 (+/- 0.03) [Accuracy 0.9854] SVC(C=2.0, random_state=17)\n",
      "ROC AUC: 0.91 (+/- 0.07) [Accuracy 0.9489] DecisionTreeClassifier(max_depth=6, random_state=17)\n",
      "ROC AUC: 0.99 (+/- 0.01) [Accuracy 0.9854] RandomForestClassifier(criterion='log_loss', n_estimators=300, random_state=17)\n",
      "ROC AUC: 0.97 (+/- 0.05) [Accuracy 0.9708] KNeighborsClassifier(n_neighbors=13)\n"
     ]
    }
   ],
   "source": [
    "# Do some cross validation on all models using AUC\n",
    "for model, accuracy in zip(best_models, model_accuracies):\n",
    "        score = cross_val_score(estimator=model,\n",
    "                                X=X_train,\n",
    "                                y=y_train,\n",
    "                                cv=10,\n",
    "                                scoring='roc_auc')\n",
    "        print(f'ROC AUC: {score.mean():.2f} '\n",
    "                f'(+/- {score.std():.2f}) [Accuracy {accuracy:.4f}]', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict over our model and save the result\n",
    "\n",
    "My first submission to Kaggle was based on the best AUC of 0.99 +/- 0.01 with an expected accuracy of 0.9854 and used the Random Forest Classifier using the log_loss criterion with 300 estimators.  Below is from my second submission, which used the Logistic Regression model to get my final submission.\n",
    "\n",
    "I then did predictions using the choice model, which was saved as the lr_best_model. Then we do the inverse transform of the class labels on the output of the prediction, cobble together a resulting dataset for submission, and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id label\n",
      "0      906564     B\n",
      "1       85715     M\n",
      "2      891670     B\n",
      "3      874217     M\n",
      "4      905680     M\n",
      "..        ...   ...\n",
      "109     87164     M\n",
      "110  84348301     M\n",
      "111    859471     B\n",
      "112    911150     B\n",
      "113  90944601     B\n",
      "\n",
      "[114 rows x 2 columns]\n",
      "csv written.\n"
     ]
    }
   ],
   "source": [
    "# Do predictions on the submission test set and save the output as csv\n",
    "data_test_input = pd.read_csv('datasets/breast-cancer-wisconsin-data/test.csv') # get the test inputs\n",
    "\n",
    "output_ids = data_test_input['id']                  # set the IDs we'll output but don't predict on them\n",
    "data_test=data_test_input.drop(labels='id', axis=1) # remove the zero-information column \"id\"\n",
    "\n",
    "X_final_test = scaler.transform(data_test)          # scale the data with the pre-existing scaler values\n",
    "\n",
    "y_pred = lr_best_model.predict(X_final_test)   # use the model to predict outcomes\n",
    "decoded_labels = encoder.inverse_transform(y_pred)  # reverse the label encoding to get B/M on the result\n",
    "\n",
    "output_df = pd.DataFrame(output_ids)                # prep a dataframe for our output\n",
    "output_df = output_df.assign(label=decoded_labels)  # append the predictions to the IDs\n",
    "\n",
    "output_df.to_csv(\"DonKrapohl_project1_submission.csv\", index=False) # write the csv\n",
    "\n",
    "print(output_df)\n",
    "\n",
    "print('csv written.')                               # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "My choice of models used Logistic Regression with C=0.75 employing the SAGA solver. Submitted to Kaggle it achieved 0.98245 accuracy.  My first submission used Random Forest and, while it scored well locally, it only got to 0.95614 over the final test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uwf-venv-breast-cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
