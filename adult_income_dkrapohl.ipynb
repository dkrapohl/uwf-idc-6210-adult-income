{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Kaggle Project 2: Adult Income Classification\n",
    "Don Krapohl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "I used looping to try out many hyperparameters to choose the best model over the preprocessed data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Predict the income level of individuals based on various demographic and personal information.\n",
    "\n",
    "- Split the provided dataset into a suitable training set and testing set.\n",
    "- Train various classifiers on your training set, including Logistic Regression, SVM, Decision Trees, KNN, and Random Forest.\n",
    "- Compare the performance of the classifiers and submit your best score.\n",
    "- Aim to beat the benchmark performance of 78% on the hidden test dataset. If your performance is lower than 78%, you will lose the entire 70% of the grade allocated for the coding portion of this assignment.\n",
    "- Note that the provided test dataset (`test.csv`) does not have target variables and is solely for testing your submission within our Kaggle system. Your training dataset (`train.csv`) is all you have, so split it appropriately for training and evaluation purposes.\n",
    "- Submit your final notebook to Canvas for peer-review.\n",
    "- In your notebook, use markdown to explain your steps, rationale, and exploration of the model's performance on various classifiers. Clearly mention which classifier you have decided on and your rationale to submit it as your final submission on Kaggle.\n",
    "- Your Kaggle team name should be exactly identical to your name in Canvas.\n",
    "- Your notebook submitted on Canvas will be peer-reviewed for further evaluation.\n",
    "- Submit your submission file on Kaggle and notebook on Canvas by Nov 17, 2024, 11:59 PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be training, testing, and using the following models:\n",
    "\n",
    "* Logistic Regression\n",
    "* SVM\n",
    "* Decision Trees\n",
    "* Random Forest\n",
    "* KNN\n",
    "\n",
    "Ref: https://scikit-learn.org/1.5/supervised_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "I will:\n",
    "* load from train.csv\n",
    "* explore the data for quality and distribution\n",
    "* discretize the continous variable \"income\"\n",
    "* scale the features\n",
    "* do feature selection to reduce dimensionality\n",
    "* remove and encode string columns\n",
    "* split the data into train and test sets\n",
    "* train all the models and select the one with the best accuracy\n",
    "    \n",
    "I'll train multiple models for each of the classifier algorithms and capture the one of each type that has the highest accuracy. After all are trained and tested I'll select the one with the highest accuracy and highest AUC as my submission.  I'll then predict over the test.csv file and submit the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish environment\n",
    "1. Download the python venv for the project from https://github.com/dkrapohl/uwf-venv-breast-cancer/tree/main (I'm using the same one from project 1)\n",
    "2. Activate the environment using the README from that repo\n",
    "3. Set the Jupyter environment to use this kernel (top right of this window)\n",
    "\n",
    "If we need to reproduce the environment the private repo for this notebook has a pip requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic dataframe and operations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# manipulation and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# measuring results\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# warning suppression\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress ConvergenceWarnings and UserWarning.  They're noise here.\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a few collections to capture the info on our different models\n",
    "\n",
    "To explore the accuracies of multiple model hyperparameters I'll be training multiple models and keeping the model from each type of classifier that has the highest accuracy.  I suspect there's an easier way to accomplish this but this is what I can do at this point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collections we'll use for our best of each type of model\n",
    "best_models = []                    # List of model instances that are our best for final evaluation\n",
    "model_accuracies = []               # The accuracies of our best models in a key-value dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll load the data into an initial dataframe to be used for exploration and the start of preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39073, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the csv training dataset to a pandas dataframe\n",
    "# The dataset is expected in the same directory as this notebook\n",
    "#   under a subfolder path datasets/breast-cancer-wisconsin-data/\n",
    "data_train = pd.read_csv('datasets/train.csv')\n",
    "# Show the shape of the dataset\n",
    "data_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Output the first 5 rows of the data to see the general character and nature of the data like missing values, obvious dirty data, features with very large ranges, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>Private</td>\n",
       "      <td>111189</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>Dominican-Republic</td>\n",
       "      <td>0</td>\n",
       "      <td>26052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>122066</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>47049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>168682</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>33915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>Private</td>\n",
       "      <td>110230</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>22132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>373050</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>46452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt     education  educational-num  \\\n",
       "0   78           Private  111189       7th-8th                4   \n",
       "1   49      Self-emp-inc  122066  Some-college               10   \n",
       "2   62  Self-emp-not-inc  168682       7th-8th                4   \n",
       "3   18           Private  110230          10th                6   \n",
       "4   40           Private  373050          12th                8   \n",
       "\n",
       "       marital-status         occupation   relationship   race  gender  \\\n",
       "0       Never-married  Machine-op-inspct  Not-in-family  White  Female   \n",
       "1            Divorced              Sales  Not-in-family  White    Male   \n",
       "2  Married-civ-spouse              Sales        Husband  White    Male   \n",
       "3       Never-married      Other-service      Own-child  White    Male   \n",
       "4  Married-civ-spouse      Other-service        Husband  White    Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week      native-country  income  \\\n",
       "0             0             0              35  Dominican-Republic       0   \n",
       "1             0             0              25       United-States       0   \n",
       "2             0             0               5       United-States       0   \n",
       "3             0             0              11       United-States       0   \n",
       "4             0             0              40                   ?       0   \n",
       "\n",
       "      id  \n",
       "0  26052  \n",
       "1  47049  \n",
       "2  33915  \n",
       "3  22132  \n",
       "4  46452  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a few rows from the training data\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the data to make sure we don't have null or missing data\n",
    "\n",
    "This will give the count of null values for each column to see if we need to handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "fnlwgt             0\n",
       "education          0\n",
       "educational-num    0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "gender             0\n",
       "capital-gain       0\n",
       "capital-loss       0\n",
       "hours-per-week     0\n",
       "native-country     0\n",
       "income             0\n",
       "id                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the count of nulls per column\n",
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "fnlwgt             0\n",
       "education          0\n",
       "educational-num    0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "gender             0\n",
       "capital-gain       0\n",
       "capital-loss       0\n",
       "hours-per-week     0\n",
       "native-country     0\n",
       "income             0\n",
       "id                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the count of nulls per column\n",
    "data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I prefer to verify object data types. Not important here but at scale it definitely is.\n",
    "\n",
    "Sometimes numeric data come in as object, which can make lookups and indexing inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39073 entries, 0 to 39072\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              39073 non-null  int64 \n",
      " 1   workclass        39073 non-null  object\n",
      " 2   fnlwgt           39073 non-null  int64 \n",
      " 3   education        39073 non-null  object\n",
      " 4   educational-num  39073 non-null  int64 \n",
      " 5   marital-status   39073 non-null  object\n",
      " 6   occupation       39073 non-null  object\n",
      " 7   relationship     39073 non-null  object\n",
      " 8   race             39073 non-null  object\n",
      " 9   gender           39073 non-null  object\n",
      " 10  capital-gain     39073 non-null  int64 \n",
      " 11  capital-loss     39073 non-null  int64 \n",
      " 12  hours-per-week   39073 non-null  int64 \n",
      " 13  native-country   39073 non-null  object\n",
      " 14  income           39073 non-null  int64 \n",
      " 15  id               39073 non-null  int64 \n",
      "dtypes: int64(8), object(8)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verify data types to see if there's a better explicit cast for any feature or if we need to encode anything\n",
    "data_train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Need to encode (index):\n",
    "> workclass - 1  \n",
    "> education - 3  \n",
    "> marital-status - 4  \n",
    "> occupation - 6  \n",
    "> relationship - 7  \n",
    "> race - 8  \n",
    "> gender - 9  \n",
    "> native-country - 13  \n",
    "    \n",
    "The other features need to be scaled (index 0, 2, 4, 10, 11, 12, 14, 15)  \n",
    "\n",
    "Income probably needs to be discretized (14)  \n",
    "\n",
    "ID needs to be removed from training (15)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the statistics about the data and their distribution.\n",
    "\n",
    "I'm looking here for any columns with differing counts and any outrageous outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39073.000000</td>\n",
       "      <td>3.907300e+04</td>\n",
       "      <td>39073.000000</td>\n",
       "      <td>39073.000000</td>\n",
       "      <td>39073.000000</td>\n",
       "      <td>39073.000000</td>\n",
       "      <td>39073.000000</td>\n",
       "      <td>39073.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.588207</td>\n",
       "      <td>1.900714e+05</td>\n",
       "      <td>10.072556</td>\n",
       "      <td>1067.195327</td>\n",
       "      <td>86.108796</td>\n",
       "      <td>40.390269</td>\n",
       "      <td>0.238144</td>\n",
       "      <td>24465.705372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.695509</td>\n",
       "      <td>1.059839e+05</td>\n",
       "      <td>2.570352</td>\n",
       "      <td>7426.475044</td>\n",
       "      <td>399.342390</td>\n",
       "      <td>12.335446</td>\n",
       "      <td>0.425953</td>\n",
       "      <td>14072.213508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175560e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12319.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.784780e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24492.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.383670e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36610.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational-num  capital-gain  \\\n",
       "count  39073.000000  3.907300e+04     39073.000000  39073.000000   \n",
       "mean      38.588207  1.900714e+05        10.072556   1067.195327   \n",
       "std       13.695509  1.059839e+05         2.570352   7426.475044   \n",
       "min       17.000000  1.349200e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.175560e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.784780e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.383670e+05        12.000000      0.000000   \n",
       "max       90.000000  1.490400e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week        income            id  \n",
       "count  39073.000000    39073.000000  39073.000000  39073.000000  \n",
       "mean      86.108796       40.390269      0.238144  24465.705372  \n",
       "std      399.342390       12.335446      0.425953  14072.213508  \n",
       "min        0.000000        1.000000      0.000000      1.000000  \n",
       "25%        0.000000       40.000000      0.000000  12319.000000  \n",
       "50%        0.000000       40.000000      0.000000  24492.000000  \n",
       "75%        0.000000       45.000000      0.000000  36610.000000  \n",
       "max     4356.000000       99.000000      1.000000  48842.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic metrics about each feature, like count, mean, std, min/max, and IQR\n",
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see that some of the features, such as capital gain/loss have huge variability with the IQR being 0 but the max is 4356."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust columns as needed\n",
    "\n",
    "1. Remove ID and make a dataframe of our target predictions. We need to remove income and ID from the training data. The former is the has no information and the latter is the value we're predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the result column from the input parameters\n",
    "# also remove the ID column. It carries no signal.\n",
    "X_train_without_label = data_train.drop('income', axis=1).drop('id', axis=1)\n",
    "\n",
    "# Assign the variable we're targeting for the input data\n",
    "y_values = data_train['income']      # assign the income continuous variable we'll discretize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Encode categorical values - I'll use the ColumnTransformer to encode multiple columns here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and scale the data\n",
    "\n",
    "Here I'll be splitting the data to be 70% training set, 30% test set. I then scale the data using the Standard Scaler to make all the data within the same range having 0 as the mean and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train test split\n",
    "X_train, X_test, y_train, y_test =    train_test_split(X_train_without_label, y_values,\n",
    "    test_size=0.3, \n",
    "    random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (27351, 1), indices imply (27351, 108)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 17\u001b[0m\n\u001b[0;32m      9\u001b[0m feature_encoder \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[0;32m     10\u001b[0m     transformers \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monehot\u001b[39m\u001b[38;5;124m'\u001b[39m, ohc, categorical_features), \n\u001b[0;32m     11\u001b[0m                     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, ss, numeric_features)],\n\u001b[0;32m     12\u001b[0m     remainder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m   \u001b[38;5;66;03m# we have the numeric columns so we want to preserve those for scaling\u001b[39;00m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m feature_encoder\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m---> 17\u001b[0m df_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m X_test_clean \u001b[38;5;241m=\u001b[39m feature_encoder\u001b[38;5;241m.\u001b[39mfit(X_test)\n\u001b[0;32m     23\u001b[0m df_transformed\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\github\\uwf-venv-breast-cancer\\Lib\\site-packages\\pandas\\core\\frame.py:867\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    859\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m             arrays,\n\u001b[0;32m    861\u001b[0m             columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 867\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    876\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    877\u001b[0m         {},\n\u001b[0;32m    878\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    882\u001b[0m     )\n",
      "File \u001b[1;32mc:\\github\\uwf-venv-breast-cancer\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\github\\uwf-venv-breast-cancer\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (27351, 1), indices imply (27351, 108)"
     ]
    }
   ],
   "source": [
    "# Make a list of string categorical cols we need to encode\n",
    "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "# Make a list of features we need to scale\n",
    "numeric_features = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "ohc = OneHotEncoder()           # creating a one hot encoder to do our column transforms\n",
    "ss = StandardScaler()           # creating a scaler for transforming\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers = [('onehot', ohc, categorical_features), \n",
    "                    ('scaler', ss, numeric_features)],\n",
    "    remainder = 'passthrough'   # we have the numeric columns so we want to preserve those for scaling\n",
    ")\n",
    "\n",
    "X_transformed = feature_encoder.fit_transform(X_train)\n",
    "\n",
    "df_transformed = pd.DataFrame(\n",
    "    X_transformed,\n",
    "    columns=feature_encoder.get_feature_names_out()\n",
    ")\n",
    "X_test_clean = feature_encoder.fit(X_test)\n",
    "\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Train and Test\n",
    "\n",
    "I'm looping through hyperparameters and training multiple models, keeping the \"best\" based on accuracy. The secondary consideration is that I will prefer the lowest C value as lower C values make simpler models.\n",
    "\n",
    "This model assumes linearity in independent variables and performs well if the data are linearly separable. It'll also give use proababilities on the class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=ColumnTransformer(remainder='passthrough',\n                  transformers=[('onehot', OneHotEncoder(),\n                                 ['workclass', 'education', 'marital-status',\n                                  'occupation', 'relationship', 'race',\n                                  'gender', 'native-country']),\n                                ('num', StandardScaler(),\n                                 ['age', 'fnlwgt', 'educational-num',\n                                  'capital-gain', 'capital-loss',\n                                  'hours-per-week'])]).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 24\u001b[0m\n\u001b[0;32m     17\u001b[0m logreg_model\u001b[38;5;241m.\u001b[39mfit(X_train_clean, y_train)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Collect info on training results if desired\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# model_train_score = logreg_model.score(X_train_scaled, y_train)                    # get the model accuracy\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# print(\"{}\\t{}\".format(\"Logistic Regression (solver={})\".format(solver), \"{:.4f}\".format(model_test_score)))\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Make predictions using training data\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlogreg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m model_test_score \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Print the accuracies for each of the model params so far.   \u001b[39;00m\n",
      "File \u001b[1;32mc:\\github\\uwf-venv-breast-cancer\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:382\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 382\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    384\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[1;32mc:\\github\\uwf-venv-breast-cancer\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:363\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    360\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    361\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 363\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\github\\uwf-venv-breast-cancer\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\github\\uwf-venv-breast-cancer\\Lib\\site-packages\\sklearn\\utils\\validation.py:1027\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1028\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1029\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1030\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1031\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1032\u001b[0m         )\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1035\u001b[0m         \u001b[38;5;66;03m# If input is a Series-like object (eg. pandas Series or polars Series)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=ColumnTransformer(remainder='passthrough',\n                  transformers=[('onehot', OneHotEncoder(),\n                                 ['workclass', 'education', 'marital-status',\n                                  'occupation', 'relationship', 'race',\n                                  'gender', 'native-country']),\n                                ('num', StandardScaler(),\n                                 ['age', 'fnlwgt', 'educational-num',\n                                  'capital-gain', 'capital-loss',\n                                  'hours-per-week'])]).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# In a loop over several values, train an SVM with different C values and capture the accuracies\n",
    "# We prefer lower C for better power so we'll only update if accuracy is higher and C lower\n",
    "\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "cs = [100.0, 50.0, 20.0, 10.0, 5.0, 3.0, 2.0, 1.0, 0.75, 0.5, 0.1, 0.01, 0.001, 0.0001]  # C values to try\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the lowest C as our \"best\" model\n",
    "lr_highest_accuracy=0\n",
    "lr_lowest_c=1000.0\n",
    "\n",
    "# Try all SVM kernels\n",
    "for solver in solvers:\n",
    "    # Try the range of C values\n",
    "    for c in cs:\n",
    "        # Initialize and train the SVM model\n",
    "        logreg_model = LogisticRegression(solver=solver, C=c, random_state = 17)\n",
    "        logreg_model.fit(X_train_clean, y_train)\n",
    "        \n",
    "        # Collect info on training results if desired\n",
    "        # model_train_score = logreg_model.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "        # print(\"{}\\t{}\".format(\"Logistic Regression (solver={})\".format(solver), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # Make predictions using training data\n",
    "        y_pred = logreg_model.predict(X_test_clean)\n",
    "        model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Print the accuracies for each of the model params so far.   \n",
    "        print(\"{}\\t{}\".format(\"Logistic Regression (solver={})\".format(solver), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # we want the lowest C for better generalization so only keep\n",
    "        #   accuracy if it's better but C is lower\n",
    "        if model_test_score >= lr_highest_accuracy: # we're in a list with decreasing values so don't need to check C\n",
    "            test_predictions = y_pred                   # store test predictions\n",
    "            lr_lowest_c = c                             # store the lowest C\n",
    "            lr_best_model = logreg_model                # store the best model\n",
    "            lr_best_solver = solver                     # store the best solver\n",
    "            lr_highest_accuracy = model_test_score       # update our highest score\n",
    "\n",
    "best_models.append(lr_best_model)                       # add to our \"best model\" collection      \n",
    "model_accuracies.append(lr_highest_accuracy)                # add the accuracy      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} solver, c {}, accuracy {}\".format(lr_best_solver, c, \"{:.4f}\".format(lr_highest_accuracy)))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Train and Test\n",
    "\n",
    "As with Logistic Regression, looping to train multiple models, keeping the one with the highest accuracy for the lowest C value.  C value again we prefer lower C as it makes for simpler models.\n",
    "\n",
    "This model will be computationally more expensive than the others, especially since I'm testing multiple C values on all kernels. The algorithm is more flexible in its ability to model both linear and non-linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a loop over several values, train an SVM with different C values and capture the accuracies\n",
    "# We prefer lower C for better power so we'll only update if accuracy is higher and C lower\n",
    "cs = [100.0, 50.0, 20.0, 10.0, 5.0, 3.0, 2.0, 1.0, 0.75, 0.5, 0.1, 0.01, 0.001, 0.0001]  # C values to try\n",
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the highest eta as our \"best\" model\n",
    "svm_highest_accuracy=0\n",
    "svm_lowest_c=1000\n",
    "\n",
    "# Try all SVM kernels\n",
    "for kernel in kernels:\n",
    "    # Loop through C values largest to smallest, train and test each\n",
    "    for c in cs:\n",
    "        # Initialize and train the SVM model\n",
    "        linear_svm = SVC(kernel=kernel, C=c, random_state=17)\n",
    "        linear_svm.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Collect info on training results if desired\n",
    "        # model_train_score = linear_svm.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "        # print(\"{}\\t{}\".format(\"SVM Train (kernel={}, C={})\".format(kernel, c), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # Make predictions using training data\n",
    "        y_pred = linear_svm.predict(X_test_scaled)\n",
    "        model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Print the accuracies for each of the model params so far.   \n",
    "        print(\"{}\\t{}\".format(\"SVM (kernel={}, C={})\".format(kernel, c), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # we want the lowest C for better generalization so only keep\n",
    "        #   accuracy if it's better but C is lower\n",
    "        if model_test_score >= svm_highest_accuracy: # we're in a list with decreasing values so don't need to check C\n",
    "            svm_lowest_c = c                            # store lowest C\n",
    "            test_predictions = y_pred                   # store test predictions\n",
    "            svm_best_model = linear_svm                 # store the best model\n",
    "            svm_best_kernel = kernel                    # store the best kernel\n",
    "            svm_highest_accuracy = model_test_score     # update our highest score\n",
    "\n",
    "best_models.append(svm_best_model)                      # add to our \"best model\" collection   \n",
    "model_accuracies.append(svm_highest_accuracy)           # add the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} kernel, accuracy {}, C {}\".format(svm_best_kernel, \"{:.4f}\".format(svm_highest_accuracy), \n",
    "                                                        svm_lowest_c))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees Train and Test\n",
    "\n",
    "With Decision Trees we're testing different splitting algorithms as well as model depth keeping the one with the highest accuracy and the lowest depth.  Lowest depth is selected as it makes for the simpler model.\n",
    "\n",
    "This algorithm should be the easiest to interpret and captures non-linear relationships but it's prone to overfitting.  It's also at risk of creating biased trees if the classes are imbalanced but the classes here are relatively equally represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a loop over several values, train a decision tree with different split criteria and depths and capture the accuracies\n",
    "# We prefer lower C for better power so we'll only update if accuracy is higher and depth lower\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the lowest depth as our \"best\" model\n",
    "dtree_highest_accuracy=0\n",
    "dtree_lowest_depth=1000\n",
    "dtree_best_criterion=''\n",
    "\n",
    "# Try all SVM kernels\n",
    "for criterion in criteria:\n",
    "    # Loop through depth values smallest to largest, train and test each\n",
    "    for depth in range(50, 1, -1):   # Allow up to depth 5 starting at 5 and down to 1\n",
    "        # Initialize and train the decision tree model\n",
    "        decision_tree = DecisionTreeClassifier(criterion=criterion, max_depth=depth, random_state=17)\n",
    "        decision_tree.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Collect info on training results if desired\n",
    "        # model_train_score = decision_tree.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "        # print(\"{}\\t{}\".format(\"Decision Tree Train (criterion={}, depth={})\".format(criterion, depth), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # Make predictions using training data\n",
    "        y_pred = decision_tree.predict(X_test_scaled)\n",
    "        model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Print the accuracies for each of the model params so far.   \n",
    "        print(\"{}\\t{}\".format(\"Decision Tree (criterion={}, depth={})\".format(criterion, depth), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # we want the lowest C for better generalization so only keep\n",
    "        #   accuracy if it's better but C is lower\n",
    "        if model_test_score >= dtree_highest_accuracy:\n",
    "            dtree_lowest_depth = depth              # store lowest depth\n",
    "            test_predictions = y_pred               # store test predictions\n",
    "            dtree_best_model = decision_tree        # store the best model\n",
    "            dtree_best_criterion = criterion        # store the best kernel\n",
    "            dtree_highest_accuracy = model_test_score   # update our highest score\n",
    "\n",
    "best_models.append(dtree_best_model)                # add to our \"best model\" collection\n",
    "model_accuracies.append(dtree_highest_accuracy)     # add the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} criterion, depth {}, accuracy {}\".format(dtree_best_criterion, dtree_lowest_depth, \n",
    "                                                               \"{:.4f}\".format(dtree_highest_accuracy)))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Train and Test\n",
    "\n",
    "This is very much like Decision Trees except we're tuning splitting criteria as well as the number of estimators used.  We'll prefer fewer estimators for simpler models.\n",
    "\n",
    "The Random Forest algorithm is harder to interpret because it's an ensemble of decision trees but it's less likely to overfit. It can be harder to compute than a single or a few decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a loop over several values, train a random forest with different split criteria and estimator count and capture the accuracies\n",
    "criteria = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the lowest number of estimators as our \"best\" model\n",
    "rforest_highest_accuracy=0\n",
    "rforest_lowest_estimators=1000\n",
    "rforest_best_criterion=''\n",
    "\n",
    "# Try all random forest split criteria\n",
    "for criterion in criteria:\n",
    "    # Loop through depth values smallest to largest, train and test each\n",
    "    for estimators in range(500, 50, -50):   # Allow up to 500 estimators decreasing by 50 each loop\n",
    "        # Initialize and train the decision tree model\n",
    "        random_forest = RandomForestClassifier(criterion=criterion, n_estimators=estimators, random_state=17)\n",
    "        random_forest.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Collect info on training results if desired\n",
    "        # model_train_score = random_forest.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "        # print(\"{}\\t{}\".format(\"Random Forest Train (criterion={}, estimators={})\".format(criterion, estimators), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # Make predictions using training data\n",
    "        y_pred = random_forest.predict(X_test_scaled)\n",
    "        model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Print the accuracies for each of the model params so far.   \n",
    "        print(\"{}\\t{}\".format(\"Random Forest Test (criterion={}, estimators={})\".format(criterion, estimators), \"{:.4f}\".format(model_test_score)))\n",
    "            \n",
    "        # we want the lowest number of estimators for better generalization \n",
    "        if model_test_score >= rforest_highest_accuracy:\n",
    "            rforest_lowest_estimators = estimators  # store lowest number of estimators\n",
    "            test_predictions = y_pred               # store test predictions\n",
    "            rforest_best_model = random_forest      # store the best model\n",
    "            rforest_best_criterion = criterion      # store the best criterion\n",
    "            rforest_highest_accuracy = model_test_score # update our highest score\n",
    "            \n",
    "best_models.append(rforest_best_model)              # add to our \"best model\" collection        \n",
    "model_accuracies.append(rforest_highest_accuracy)   # add the accuracy    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} criterion, estimators {}, accuracy {}\".format(rforest_best_criterion, rforest_lowest_estimators, \n",
    "                                                                    \"{:.4f}\".format(rforest_highest_accuracy)))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Train and Test\n",
    "\n",
    "This is simpler as I'm only tuning the number of neighbors and keeping the one with the highest accuracy. We'll prefer the model with the fewest neighbors.\n",
    "\n",
    "KNN, while computational a bit expensive is simple for this problem and doesn't appear to require much tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a loop over several values, train a knn movel with different number of neighbors\n",
    "\n",
    "# I'll also keep track of the highest accuracy for the lowest # nieghbors as our \"best\" model\n",
    "knn_highest_accuracy=0\n",
    "knn_lowest_neighbors=1\n",
    "\n",
    "# Loop through neighbor values, train and test each\n",
    "for n_neighbors in range(2, 50):   # Allow up to 50 neighbors increasing by 1 each loop\n",
    "    # Initialize and train the decision tree model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Collect info on training results if desired\n",
    "    # model_train_score = knn_model.score(X_train_scaled, y_train)                    # get the model accuracy\n",
    "    # print(\"{}\\t{}\".format(\"KNN Train (neighbors={})\".format(n_neighbors), \"{:.4f}\".format(model_test_score)))\n",
    "        \n",
    "    # Make predictions using training data\n",
    "    y_pred = knn_model.predict(X_test_scaled)\n",
    "    model_test_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print the accuracies for each of the model params so far.   \n",
    "    print(\"{}\\t{}\".format(\"KNN Test (neighbors={})\".format(n_neighbors), \"{:.4f}\".format(model_test_score)))\n",
    "        \n",
    "    # we want the lowest number of estimators for better generalization \n",
    "    if model_test_score >= knn_highest_accuracy:\n",
    "        knn_lowest_neighbors = n_neighbors      # store lowest number of estimators\n",
    "        test_predictions = y_pred               # store test predictions\n",
    "        knn_best_model = knn_model              # store the best model\n",
    "        knn_highest_accuracy = model_test_score # update our highest score\n",
    "\n",
    "best_models.append(knn_best_model)              # add to our \"best model\" collection  \n",
    "model_accuracies.append(knn_highest_accuracy)   # add the accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best model info\n",
    "print(\"Best model: {} neighbors, accuracy {}\".format(knn_lowest_neighbors, \"{:.4f}\".format(knn_highest_accuracy)))\n",
    "\n",
    "# Print the confusion matrix for the best model\n",
    "print(\"Model Confusion Matrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "print(\"Train data F1-Score for class '1':\", f1_score(y_test, test_predictions, pos_label=1))\n",
    "print(\"Train data F1-Score for class '0':\", f1_score(y_test, test_predictions, pos_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Selection\n",
    "\n",
    "Here I enumerate through the best model for each type of classifier; do cross validation; and output AUC, accuracy, and info on the hyperparameters of our best of each type of model.  I'll use this to select the best model.\n",
    "\n",
    "The best model I will choose is the one with the highest AUC that has the lowest standard deviation and the one with the highest accuracy.\n",
    "\n",
    "After this I will load the test.csv we need to predict over, do predictions, encode the class label outputs of the predictions, and save the final csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some cross validation on all models using AUC\n",
    "for model, accuracy in zip(best_models, model_accuracies):\n",
    "        score = cross_val_score(estimator=model,\n",
    "                                X=X_train,\n",
    "                                y=y_train,\n",
    "                                cv=10,\n",
    "                                scoring='roc_auc')\n",
    "        print(f'ROC AUC: {score.mean():.2f} '\n",
    "                f'(+/- {score.std():.2f}) [Accuracy {accuracy:.4f}]', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict over our model and save the result\n",
    "\n",
    "My first submission to Kaggle was based on the best AUC of 0.99 +/- 0.01 with an expected accuracy of 0.9854 and used the Random Forest Classifier using the log_loss criterion with 300 estimators.  Below is from my second submission, which used the Logistic Regression model to get my final submission.\n",
    "\n",
    "I then did predictions using the choice model, which was saved as the lr_best_model. Then we do the inverse transform of the class labels on the output of the prediction, cobble together a resulting dataset for submission, and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do predictions on the submission test set and save the output as csv\n",
    "data_test_input = pd.read_csv('datasets/breast-cancer-wisconsin-data/test.csv') # get the test inputs\n",
    "\n",
    "output_ids = data_test_input['id']                  # set the IDs we'll output but don't predict on them\n",
    "data_test=data_test_input.drop(labels='id', axis=1) # remove the zero-information column \"id\"\n",
    "\n",
    "X_final_test = scaler.transform(data_test)          # scale the data with the pre-existing scaler values\n",
    "\n",
    "y_pred = lr_best_model.predict(X_final_test)   # use the model to predict outcomes\n",
    "decoded_labels = encoder.inverse_transform(y_pred)  # reverse the label encoding to get B/M on the result\n",
    "\n",
    "output_df = pd.DataFrame(output_ids)                # prep a dataframe for our output\n",
    "output_df = output_df.assign(label=decoded_labels)  # append the predictions to the IDs\n",
    "\n",
    "output_df.to_csv(\"DonKrapohl_project1_submission.csv\", index=False) # write the csv\n",
    "\n",
    "print(output_df)\n",
    "\n",
    "print('csv written.')                               # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "My choice of models used Logistic Regression with C=0.75 employing the SAGA solver. Submitted to Kaggle it achieved 0.98245 accuracy.  My first submission used Random Forest and, while it scored well locally, it only got to 0.95614 over the final test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uwf-venv-breast-cancer",
   "language": "python",
   "name": "uwf-venv-breast-cancer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
